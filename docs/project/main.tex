\documentclass{article}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{tcolorbox}
\usepackage{xcolor}
\usepackage{amsmath}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\usepackage{listings}
\lstset{
    literate={"}{{\texttt{"}}}1
             {'}{{\texttt{'}}}1
             {~}{{\texttt{~}}}1
             { }{{\ }}1
}
\lstdefinestyle{code}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=t,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=C++
}

\lstdefinestyle{output}{
    backgroundcolor=\color{black!5},
    basicstyle=\ttfamily\small,
    breaklines=true,
    showstringspaces=false,
    frame=single,
    rulecolor=\color{black!20},
    numbers=none,
    captionpos=t,
    language=bash
}

\renewcommand{\lstlistingname}{Code block}

\newcounter{exercise}
\newenvironment{exr}[1]{%
    \refstepcounter{exercise}
    \begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=Exercise \theexercise]
    \textbf{Instructions:} #1
    \end{tcolorbox}
    \vspace{1em}
}{}

\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

\title{
    TAC-HEP GPU Programming Training Module: Final project
}

\author{Roy F. Cruz}

\begin{document}

\date{December 11, 2025}
\maketitle

The GitHub repository that hosts this code can be accessed via the following link: \href{https://github.com/roy-cruz/TAC-HEP_GPU-Course_Assignments/tree/master}{link}

\section{C++ and CPU Profiling}
\begin{exr}{
    \begin{itemize}
        \item Start by writing a code in C++ that:
        \begin{itemize}
            \item Creates two 2-dimensional square matrices \texttt{A} and \texttt{B} of size \texttt{DSIZE >= 512}   and fills them with arbitrary integer values.
            \item Performs a 2-dimensional stencil operation on each matrix. You can use any radius size, but keep it \texttt{> 2}.
            \item Performs a matrix multiplication of the matrices after the stencil application.
            \item Make sure that you also add utility functions to check your results.
        \end{itemize}
        \item Profile your C++ code using the VTune profiler and identify the compute intensive parts.
    \end{itemize}
    }
\end{exr}

The CPU implementation of the matrix stencil and multiplication code uses the two serial functions shown in the following code snippet.

\lstinputlisting[caption={\texttt{stencil\_mult.cpp}}, style=code, firstline=7,lastline=35]{../../project/ex1-cpu/stencil_mult.cpp}


This code served as the baseline for the other versions of the code. The following shows the outcome of the progiling, which shows that the execution took an effective time of $5.240 \text{ s}$, $99.6\%$ out of which was just spent on the matrix multiplication, which dominated all other parts of the code. The \texttt{compute_stencil}, on the other hand, only took up $0.020 \text{ s}$, or $0.4\%$ of the time.



% \begin{lstlisting}[style=output]
% [rcruzcan@g37n01 project]$ vtune -report summary -result-dir ./profiling/cpu_hotspots/
% vtune: Using result path `/mnt/ceph/home/rcruzcan/private/courses/GPUProg/tac-hep-gpus-roycruz/project/profiling/cpu_hotspots'
% vtune: Executing actions 75 % Generating a report                              Elapsed Time: 5.248s
%     CPU Time: 5.240s
%         Effective Time: 5.240s
%         Spin Time: 0s
%         Overhead Time: 0s
%     Total Thread Count: 1
%     Paused Time: 0s

% Top Hotspots
% Function         Module            CPU Time  % of CPU Time(%)
% ---------------  ----------------  --------  ----------------
% matrix_mult      stencil_mult_cpu    5.220s             99.6%
% compute_stencil  stencil_mult_cpu    0.020s              0.4%
% Collection and Platform Info
%     Application Command Line: objs/stencil_mult_cpu
%     Operating System: 6.1.156-1.el9.elrepo.x86_64 \S Kernel \r on an \m
%     Computer Name: g37n01.hep.wisc.edu
%     Result Size: 3.7 MB
%     Collection start time: 06:39:47 11/12/2025 UTC
%     Collection stop time: 06:39:53 11/12/2025 UTC
%     Collector Type: User-mode sampling and tracing
%     CPU
%         Name: Unknown
%         Frequency: 3.000 GHz
%         Logical CPU Count: 64
%         Cache Allocation Technology
%             Level 2 capability: not detected
%             Level 3 capability: available
% \end{lstlisting}


% ------------------------------------------------------------------------

\section{Porting to CUDA}
\begin{exr}{
    \begin{itemize}
        \item Write the same application in CUDA:
        \begin{itemize}
            \item You should write a CUDA kernel that performs the stencil operation and one for the matrix multiplication.
            \item Initially make use of explicit memory copies from host to device and vice-versa and make use only of the default CUDA stream.
            \item Make sure to add utility functions for error checking and for verifying your results.
        \end{itemize}
        \item Profile your code using nsys and document/comment on the time spent in each CUDA API call. Also, make note of the time spent on host and device.
        \item Try switching from explicit memory copies to managed memory.
        \begin{itemize}
            \item Profile again using either nsys on ncu and comment on the performance of your application
        \end{itemize}
    \end{itemize}
}\end{exr}

\lstinputlisting[caption={\texttt{compute\_funcs\_ex2.h}}, style=code]{../../project/hh/compute_funcs_ex2.h}

\lstinputlisting[caption={\texttt{stencil\_mult\_explicit.cu}}, style=code]{../../project/ex2-cuda/stencil_mult_explicit.cu}
\lstinputlisting[caption={\texttt{stencil\_mult\_managed.cu}}, style=code]{../../project/ex2-cuda/stencil_mult_managed.cu}

% ------------------------------------------------------------------------
\section{Optimizing Performance in CUDA}
\begin{exr}{
    \begin{itemize}
        \item Optimize the performance of your code making use of non-default CUDA streams and shared memory.
        \item Once you have decided on the best approach, profile your application and compare the time spent in each API call and the overall timing of your application with your initial CUDA implementation.
    \end{itemize}
}\end{exr}

\lstinputlisting[caption={\texttt{compute\_funcs\_ex3.h}}, style=code]{../../project/hh/compute_funcs_ex3.h}

\lstinputlisting[caption={\texttt{stencil\_mult\_managed.cu}}, style=code]{../../project/ex3-cudaopt/stencil_mult_opt.cu}

% ------------------------------------------------------------------------
\section{Making Use of Alpaka}
\begin{exr}{
    \begin{itemize}
        \item Re-write your application making use of the Alpaka portability library.
        \item Describe the steps you had to follow to re-write your code.
    \end{itemize}
}\end{exr}


% ------------------------------------------------------------------------
\newpage
\appendix

\section{Setup Description}

This project was developed and run on a GPU node on the Wisconsin Analysis Facility. In this computing system, setting up CUDA for compilation consisted of running

\begin{lstlisting}[style=output]
export PATH=$PATH:/usr/local/cuda/bin
export LD_LIBRARY_PATH=/usr/local/cuda/lib
\end{lstlisting}

To compile the implementation of the code that uses Alpaka, we followed the setup instructions provided in the Alpaka lecture, which consisted of simply cloning the official Alpaka repo by running the following command.

\begin{lstlisting}[style=output]
git clone https://github.com/alpaka-group/alpaka.git -b 2.0.0 ${HOME}/public/alpaka
\end{lstlisting}

In order conveniently re-run the compilation of the code during development, a Make file was constructed. In this file, the compilation of the different versions of the matrix stenciling and multiplication code were compiled using the following commands.

\begin{lstlisting}[style=output]
g++ ex1-cpu/stencil_mult.cpp -o objs/stencil_mult_cpu -O3 -g -I ./hh
nvcc ex2-cuda/stencil_mult_explicit.cu -o objs/stencil_mult_explicit -O3 -I ./hh
nvcc ex2-cuda/stencil_mult_managed.cu -o objs/stencil_mult_managed -O3 -I ./hh
nvcc ex3-cudaopt/stencil_mult_opt.cu -o objs/stencil_mult_opt -O3 -I ./hh
nvcc ex4-alpaka/stencil_mult_alpaka.cpp -o objs/stencil_mult_alpaka -x cu -expt-relaxed-constexpr -std=c++20 -O3 -g -I /mnt/ceph/home/rcruzcan/public/alpaka/include -D ALPAKA_ACC_GPU_CUDA_ENABLED -I ./hh -Wno-deprecated-declarations
\end{lstlisting}

Note that the \texttt{hh} directory contained a collection of header files with utilities used by the different version of the implemented algorithm. Of particular note are \texttt{config.h} and \texttt{WorkDiv.hpp}, which contain helpful utilities for the Alpaka version of the code, and which were fetched from \href{https://github.com/fwyzard/intro_to_alpaka/tree/master/alpaka}{this} repository that was part of the instructional material for the Alpaka lecture. 



\section{Results Validation}


\end{document}